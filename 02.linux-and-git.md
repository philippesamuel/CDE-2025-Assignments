# 02. Linux and Git

## 1. ETL process with bash script.
- **Extract**:
  - [ ] Download a csv file and save it into `raw` folder.
  - [ ] Confirm that the file has been saved in the `raw` folder.

```bash
#!/bin/bash

export RAW_CSV_URL=https://www.stats.govt.nz/assets/Uploads/Annual-enterprise-survey/Annual-enterprise-survey-2023-financial-year-provisional/Download-data/annual-enterprise-survey-2023-financial-year-provisional.csv
RAW_CSV_PATH=raw/2023_year_finance.csv
TRANSFORMED_CSV_PATH=transformed/2023_year_finance.csv
LOAD_CSV_PATH=gold/2023_year_finance.csv

# create necessery folders
mkdir raw transformed gold

# download csv file
curl -o $RAW_CSV_PATH $RAW_CSV_URL

# test that file exists
if [ -f "$RAW_CSV_PATH" ]; then
  echo "$RAW_CSV_PATH exists."
fi

```

- **Transform**:
  - [ ] Rename the column `Variable_code` to `variable_code`
  - [ ] Select columns `year, Value, Units, variable_code`
  - [ ] Save to `transformed/2023_year_finance.csv`
 
```bash
# read first line
# indices of desired columns `year, Value, Units, variable_code`
# 1, 9, 5, 6 (I'm too lazy to automate that now)

CSV_HEADER_RAW=$(head -n 1 $RAW_CSV_PATH | cut -d, -f1,9,5,6)
echo "${CSV_HEADER_RAW/Variable_code/variable_code}" > $TRANSFORMED_CSV_PATH
sed '1d' $RAW_CSV_PATH | cut -d, -f1,9,5,6 >> $TRANSFORMED_CSV_PATH

```

- **Load**:
  - [ ] Load transformed data to `gold`.
  - [ ] Confirm that the file has been saved in the `gold` folder.
 
```bash
cp $TRANSFORMED_CSV_PATH $LOAD_CSV_PATH

# test that file exists
if [ -f "$LOAD_CSV_PATH" ]; then
  echo "$LOAD_CSV_PATH exists."
fi

```

 
- Further requirements:
  - [ ] Use environment variables for the url.
  - [ ] Well-detailed script.
  - [ ] Comment.
  - [ ] Print information for each step.

# 02. Cron job

Check [`./src/02.linux-and-git/example.crontab`](./src/02.linux-and-git/example.crontab)

# 03. Bash script to move CSV and JSON

Check [`./src/02.linux-and-git/move-csv-and-json.sh`](./src/02.linux-and-git/move-csv-and-json.sh)

# 04. Analyse `Parch and Posey` competition

```bash

DATA_URL=https://github.com/jdbarillas/parchposey/tree/master/data-raw

# iterates over each csv file and copy to PostgreSQL database `posey`.

# SQL queries:


```
SELECT id FROM ... WHERE (gloss_qty > 4000) OR (poster_qty > 4000);

SELECT * FROM ... WHERE (standart_qty = 0) AND (gloss_qty > 1000) OR (poster_qty > 1000);

SELECT ... FROM ... WHERE ((name LIKE 'C%') or (name LIKE 'W%')) AND (contact LIKE '%ana%' AND contact NOT LIKE '%eana%')

SELECT region_name, sales_rep_name, account_name FROM ... JOIN ... SORT BY account_name

